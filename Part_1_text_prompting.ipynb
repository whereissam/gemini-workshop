{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whereissam/gemini-workshop/blob/main/Part_1_text_prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSc7AU66mJSC"
      },
      "source": [
        "##### Copyright 2025 Patrick Loeber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tc6tjo9vmJSE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuC_VSKMcEt6"
      },
      "source": [
        "# Workshop: Build with Gemini (Part 1)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-1-text-prompting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This workshop teaches how to build with Gemini using the Gemini API and Python SDK.\n",
        "\n",
        "Course outline:\n",
        "\n",
        "- **Part1 (this notebook): Quickstart + Text prompting**\n",
        "  - Text understanding\n",
        "  - Streaming response\n",
        "  - Chats\n",
        "  - System prompts\n",
        "  - Config options\n",
        "  - Long context\n",
        "  - Token usage\n",
        "  - Final excercise: Chat with book\n",
        "\n",
        "- **[Part 2: Multimodal understanding (image, video, audio, docs, code)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-2-multimodal-understanding.ipynb)**\n",
        "\n",
        "- **[Part 3: Thinking models + agentic capabilities (tool usage)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-3-thinking-and-tools.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRVsnMMJvof"
      },
      "source": [
        "## 0. Use the Google AI Studio as playground\n",
        "\n",
        "Explore and play with all models in the [Google AI Studio](https://aistudio.google.com/apikey).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnl6q8tMcpwU"
      },
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD1kaBP4dnZG"
      },
      "source": [
        "Get a free API key in the [Google AI Studio](https://aistudio.google.com/apikey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6raUs82eYfk"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKjUEGGzdp87"
      },
      "source": [
        "Install the [Google Gen AI Python SDK](https://github.com/googleapis/python-genai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4d9NjqNeAXx"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b7d1FleDuz"
      },
      "source": [
        "Configure Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6Uort3heUqT"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P2KmoPSgRxO"
      },
      "source": [
        "Configure model. See all [models](https://ai.google.dev/gemini-api/docs/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qcgiiP7gO-6"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gemini-2.0-flash\" # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLsGbeGec8iF"
      },
      "source": [
        "## 2. Send your first prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e57RFdZ6dRro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc6592a-78aa-4be3-d37e-438beb146b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down how Artificial Intelligence (AI) works in a way that's understandable.  Think of it like this: AI isn't a single magical thing, but rather a collection of techniques and approaches that allow computers to perform tasks that typically require human intelligence.\n",
            "\n",
            "**The Core Idea: Learning from Data**\n",
            "\n",
            "At its heart, most AI relies on the idea of **learning from data**.  Instead of being explicitly programmed with specific instructions for *every* situation, AI systems are given vast amounts of data and algorithms that enable them to:\n",
            "\n",
            "1.  **Identify Patterns:**  The AI looks for patterns, correlations, and relationships within the data.\n",
            "2.  **Build a Model:**  Based on the identified patterns, the AI creates a model (a representation) of the underlying relationships. This model could be a set of rules, a complex mathematical equation, or a neural network.\n",
            "3.  **Make Predictions or Decisions:**  When new data is presented, the AI uses its model to make predictions, classifications, or decisions.\n",
            "4.  **Improve Over Time:**  The AI can then learn from its successes and failures, refining its model to improve its accuracy and performance.  This is often called \"training.\"\n",
            "\n",
            "**Key AI Techniques:**\n",
            "\n",
            "Here are some of the most common and important techniques used in AI:\n",
            "\n",
            "*   **Machine Learning (ML):**  This is a broad category where AI systems learn from data without being explicitly programmed.  It's the foundation of many AI applications.\n",
            "\n",
            "    *   **Supervised Learning:**  The AI is trained on labeled data (data where the correct answer is already known).  For example, you might train an image recognition AI with thousands of images of cats and dogs, labeling each image with \"cat\" or \"dog\".  The AI learns to associate features in the images (e.g., pointy ears, furry tail) with the correct label.  Examples include:\n",
            "        *   **Classification:** Assigning data to categories (e.g., spam/not spam).\n",
            "        *   **Regression:** Predicting a continuous value (e.g., predicting house prices).\n",
            "\n",
            "    *   **Unsupervised Learning:**  The AI is given unlabeled data and must find patterns and structures on its own.  For example, you might give the AI a dataset of customer purchase histories and it might identify different customer segments (e.g., \"high-spending loyal customers\", \"occasional bargain hunters\").  Examples include:\n",
            "        *   **Clustering:** Grouping similar data points together.\n",
            "        *   **Dimensionality Reduction:** Simplifying data by reducing the number of variables.\n",
            "        *   **Anomaly Detection:** Identifying unusual data points.\n",
            "\n",
            "    *   **Reinforcement Learning (RL):**  The AI learns by interacting with an environment and receiving rewards or penalties for its actions. Think of it like training a dog with treats. The AI tries different actions to maximize its cumulative reward.  This is often used in robotics and game playing.\n",
            "\n",
            "*   **Neural Networks (NNs) and Deep Learning (DL):**  Neural networks are inspired by the structure of the human brain. They consist of interconnected nodes (neurons) organized in layers.  Data flows through the network, and the connections between nodes are adjusted during training to improve accuracy.  \"Deep Learning\" is a type of machine learning that uses neural networks with many layers (hence \"deep\") to learn complex patterns.  Deep Learning is responsible for many of the recent breakthroughs in AI, such as image recognition, natural language processing, and speech recognition.\n",
            "\n",
            "*   **Natural Language Processing (NLP):**  This focuses on enabling computers to understand, interpret, and generate human language.  It involves tasks like:\n",
            "    *   **Text Analysis:**  Extracting meaning and information from text.\n",
            "    *   **Sentiment Analysis:** Determining the emotional tone of text.\n",
            "    *   **Machine Translation:** Translating text from one language to another.\n",
            "    *   **Chatbots:**  Creating conversational AI agents.\n",
            "\n",
            "*   **Computer Vision:**  This enables computers to \"see\" and interpret images and videos.  It involves tasks like:\n",
            "    *   **Image Recognition:** Identifying objects in images.\n",
            "    *   **Object Detection:**  Locating objects within an image.\n",
            "    *   **Image Segmentation:**  Dividing an image into regions.\n",
            "\n",
            "*   **Robotics:**  This combines AI with engineering to create robots that can perform tasks autonomously. AI is used for:\n",
            "    *   **Navigation:**  Guiding robots through their environment.\n",
            "    *   **Object Manipulation:**  Enabling robots to grasp and move objects.\n",
            "    *   **Decision Making:**  Allowing robots to make choices based on their surroundings.\n",
            "\n",
            "*   **Expert Systems:**  These are AI systems designed to mimic the decision-making abilities of a human expert in a specific domain.  They typically use a knowledge base and a set of rules to provide advice or solutions.  While less common now due to the rise of machine learning, they were an early form of AI.\n",
            "\n",
            "**The Process in More Detail (Using Supervised Learning as an Example):**\n",
            "\n",
            "1.  **Data Collection:** Gather a large dataset of labeled data relevant to the task. The quality and quantity of the data are crucial. \"Garbage in, garbage out\" is a common saying in AI.\n",
            "\n",
            "2.  **Data Preprocessing:**  Clean and prepare the data. This might involve:\n",
            "    *   **Handling Missing Values:** Filling in missing data points.\n",
            "    *   **Data Transformation:** Converting data into a suitable format.\n",
            "    *   **Feature Extraction:** Identifying the relevant features (characteristics) in the data that the AI should focus on.\n",
            "\n",
            "3.  **Model Selection:** Choose an appropriate AI model based on the type of problem and the characteristics of the data.  For example, a neural network might be suitable for image recognition, while a decision tree might be better for a simpler classification task.\n",
            "\n",
            "4.  **Training:** Train the AI model using the prepared data.  This involves feeding the data into the model and adjusting its parameters (internal settings) to minimize errors.  The training process often involves splitting the data into:\n",
            "    *   **Training Set:** Used to train the model.\n",
            "    *   **Validation Set:** Used to monitor the model's performance during training and prevent overfitting (where the model learns the training data *too* well and performs poorly on new data).\n",
            "\n",
            "5.  **Testing:** Evaluate the trained model on a separate, unseen dataset (the \"test set\") to assess its generalization performance (how well it performs on new, real-world data).\n",
            "\n",
            "6.  **Deployment:**  Deploy the trained model into a real-world application.\n",
            "\n",
            "7.  **Monitoring and Retraining:** Continuously monitor the model's performance and retrain it periodically with new data to maintain accuracy and adapt to changing conditions.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Bias:** AI models can inherit biases present in the training data.  This can lead to unfair or discriminatory outcomes.  It's crucial to be aware of and address potential biases in the data.\n",
            "*   **Explainability:** Some AI models (especially deep learning models) are \"black boxes,\" meaning it's difficult to understand why they make certain decisions.  This lack of explainability can be a problem in sensitive applications where transparency is important.\n",
            "*   **Ethics:** The development and use of AI raise important ethical considerations, such as job displacement, privacy, and security.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "AI works by enabling computers to learn from data, build models, and make predictions or decisions.  It encompasses a wide range of techniques, including machine learning, neural networks, natural language processing, and computer vision.  While AI has the potential to solve many problems and improve our lives, it's important to be aware of its limitations and ethical implications.\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=\"Explain how AI works\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rfjqevtmRBO"
      },
      "source": [
        "#### **!! Exercise !!**\n",
        "- Send a few more prompts\n",
        "  - Tell Gemini to write a blog post about the transformers architecture\n",
        "  - Ask Gemini to explain list comprehension in Python\n",
        "- Experiment with models:\n",
        "  - Try Gemini 2.0 Flash-Lite\n",
        "  - Try Gemini 2.5 Pro Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Zj8kiIoRqn"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHqnTYJFdSlG"
      },
      "source": [
        "## 3. Text understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHRVaK0-tCE_"
      },
      "source": [
        "The simplest way to generate text is to provide the model with a text-only prompt. `contents` can be a single prompt, a list of prompts, or a combination of multimodal inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_HqjSiFsUQ2"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=\"Explain how AI works, history\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itCzXz1BiG5g"
      },
      "source": [
        "#### Streaming response\n",
        "\n",
        "By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by using streaming to return outputs as they're generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d6HzwfZdWbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846c6e92-afb9-4690-e883-4e60c0ba8f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let\n",
            "________________________________________________________________________________\n",
            "'s break down how AI works, particularly focusing on the principles behind AI models\n",
            "________________________________________________________________________________\n",
            " like those developed by OpenAI.  It's a vast topic, so we'll hit\n",
            "________________________________________________________________________________\n",
            " the key concepts and then drill down a bit on the specific techniques OpenAI often employs.\n",
            "\n",
            "**The Core Idea: Learning from Data**\n",
            "\n",
            "At its heart,\n",
            "________________________________________________________________________________\n",
            " AI, especially the kind that powers ChatGPT and similar systems, is about enabling computers to *learn from data* without being explicitly programmed for every possible scenario.  Instead of rigid\n",
            "________________________________________________________________________________\n",
            ", step-by-step instructions, AI systems are trained on massive datasets, allowing them to identify patterns, make predictions, and generate human-like text, images, or other outputs.\n",
            "\n",
            "Think of it like teaching a child to recognize\n",
            "________________________________________________________________________________\n",
            " a cat.  You don't give them a detailed checklist (\"triangular ears, whiskers, four legs...\").  Instead, you show them many, many pictures of cats.  Eventually, the child (and the AI!) learns\n",
            "________________________________________________________________________________\n",
            " to recognize the *general* concept of \"cat-ness,\" even if it's a cat they've never seen before.\n",
            "\n",
            "**Key Components of AI Systems:**\n",
            "\n",
            "1.  **Data:** This is the lifeblood of AI.  The more data an AI model has access to, the better it can learn and\n",
            "________________________________________________________________________________\n",
            " generalize.  The quality of the data is also critical – \"garbage in, garbage out\" applies here.  Data can be text, images, audio, video, sensor readings, or anything else that can be represented digitally.\n",
            "\n",
            "2.  **Algorithms (Models):** These are the mathematical recipes that tell the AI\n",
            "________________________________________________________________________________\n",
            " how to learn from the data.  There are many different types of algorithms, each suited for different tasks. Some common examples include:\n",
            "\n",
            "    *   **Linear Regression:**  Predicting a continuous value based on a linear relationship with input features (e.g., predicting house prices based on square footage).\n",
            "    \n",
            "________________________________________________________________________________\n",
            "*   **Logistic Regression:**  Predicting a binary outcome (e.g., spam or not spam).\n",
            "    *   **Decision Trees:**  Creating a tree-like structure to classify data based on a series of decisions.\n",
            "    *   **Support Vector Machines (SVMs):** Finding the optimal boundary between\n",
            "________________________________________________________________________________\n",
            " different classes of data.\n",
            "    *   ****Neural Networks (Crucial for OpenAI Models):**  Simulating the structure of the human brain, these are composed of interconnected nodes (neurons) organized in layers.  Neural networks are particularly good at learning complex patterns.  More on this below.\n",
            "\n",
            "3.\n",
            "________________________________________________________________________________\n",
            "  **Training:** This is the process of feeding the data to the algorithm and allowing it to adjust its internal parameters to improve its performance.  There are different training methods:\n",
            "\n",
            "    *   **Supervised Learning:**  The model is trained on labeled data (e.g., images of cats labeled as \"cat\").\n",
            "________________________________________________________________________________\n",
            " The model learns to map inputs to outputs.\n",
            "    *   **Unsupervised Learning:**  The model is trained on unlabeled data and must discover patterns and relationships on its own (e.g., clustering customers into different segments based on their purchasing behavior).\n",
            "    *   **Reinforcement Learning:** The model learns by trial\n",
            "________________________________________________________________________________\n",
            " and error, receiving rewards or penalties for its actions (e.g., training a robot to walk).\n",
            "\n",
            "4.  **Inference:** Once the model is trained, it can be used to make predictions or generate outputs on new, unseen data.  This is the \"doing\" part of AI.  You give the model\n",
            "________________________________________________________________________________\n",
            " an input, and it gives you an output based on what it learned during training.\n",
            "\n",
            "**Deep Dive: How OpenAI Models Work (Mostly Using Neural Networks)**\n",
            "\n",
            "OpenAI's models, like GPT (Generative Pre-trained Transformer) and DALL-E, rely heavily on **deep learning**, which is\n",
            "________________________________________________________________________________\n",
            " a subfield of AI that uses **artificial neural networks** with many layers (hence \"deep\"). Here's a simplified explanation:\n",
            "\n",
            "*   **Neural Network Architecture:**  A neural network consists of layers of interconnected nodes (\"neurons\").\n",
            "\n",
            "    *   **Input Layer:** Receives the initial data (e.g.,\n",
            "________________________________________________________________________________\n",
            " words in a sentence).\n",
            "    *   **Hidden Layers:** Perform complex calculations on the data.  The more layers, the more complex the patterns the network can learn.  This is where the \"deep\" in deep learning comes from.\n",
            "    *   **Output Layer:** Produces the final result (e\n",
            "________________________________________________________________________________\n",
            ".g., the next word in a sentence).\n",
            "\n",
            "*   **Connections and Weights:**  The connections between neurons have associated \"weights.\" These weights determine the strength of the connection – how much influence one neuron has on another.\n",
            "\n",
            "*   **Activation Functions:** Each neuron applies an \"activation function\" to its input. This function\n",
            "________________________________________________________________________________\n",
            " determines whether the neuron \"fires\" and passes its output to the next layer.  Activation functions introduce non-linearity, which is crucial for learning complex patterns.\n",
            "\n",
            "*   **Training Process (Backpropagation):**\n",
            "\n",
            "    1.  **Forward Pass:** The input data is fed through the network, layer by layer, to\n",
            "________________________________________________________________________________\n",
            " produce an output.\n",
            "    2.  **Calculate Error:** The output is compared to the desired output (if supervised learning). The difference is the \"error.\"\n",
            "    3.  **Backpropagation:** The error is propagated backward through the network, and the weights are adjusted to reduce the error.  This is\n",
            "________________________________________________________________________________\n",
            " done using calculus (specifically, gradient descent).  The goal is to find the set of weights that minimizes the error.\n",
            "    4.  **Repeat:** Steps 1-3 are repeated many times with different data samples until the network's performance converges (stops improving significantly).\n",
            "\n",
            "*   **Transformers (Key\n",
            "________________________________________________________________________________\n",
            " to GPT):** OpenAI's GPT models are based on a specific type of neural network architecture called a \"Transformer.\"  Transformers are particularly good at handling sequential data like text.  Key features of Transformers:\n",
            "\n",
            "    *   **Attention Mechanism:**  Allows the model to focus on the most relevant parts of the input when\n",
            "________________________________________________________________________________\n",
            " making predictions.  For example, when generating the word \"France,\" the model might pay more attention to the words \"capital of\" and \"Paris.\"  This is a huge improvement over older recurrent neural networks (RNNs) which struggled with long-range dependencies.\n",
            "    *   **Parallel Processing:**  Transformers\n",
            "________________________________________________________________________________\n",
            " can process the entire input sequence in parallel, making them much faster to train than RNNs.\n",
            "    *   **Self-Attention:** The attention mechanism is applied to the input sequence itself, allowing the model to understand the relationships between different parts of the input.\n",
            "\n",
            "*   **Pre-training and Fine-tuning:**\n",
            "________________________________________________________________________________\n",
            "  OpenAI models are often \"pre-trained\" on massive amounts of data.  This gives them a general understanding of language, images, or other domains.  Then, they are \"fine-tuned\" on a smaller, more specific dataset to optimize their performance for a particular task.\n",
            "\n",
            "**Example: Generating\n",
            "________________________________________________________________________________\n",
            " Text with GPT**\n",
            "\n",
            "1.  **Input:** You type a prompt, like \"Write a short story about a cat who can talk.\"\n",
            "2.  **Tokenization:** The prompt is broken down into smaller units called \"tokens\" (e.g., words, parts of words, punctuation).\n",
            "3.\n",
            "________________________________________________________________________________\n",
            "  **Encoding:**  Each token is converted into a numerical representation (a vector) that the neural network can understand.\n",
            "4.  **Transformer Processing:** The encoded tokens are fed into the Transformer network. The attention mechanism helps the network understand the relationships between the words in the prompt.\n",
            "5.  **Prediction:** The\n",
            "________________________________________________________________________________\n",
            " network predicts the probability of each possible token being the next word in the story.\n",
            "6.  **Sampling:** A token is selected based on the predicted probabilities.  This can be done in various ways (e.g., choosing the most likely token, randomly sampling from the top few tokens).\n",
            "7.  **Decoding\n",
            "________________________________________________________________________________\n",
            ":** The selected token is converted back into a word.\n",
            "8.  **Iteration:** Steps 5-7 are repeated to generate the rest of the story, one word at a time.  The generated words are added to the input sequence, so the model can use them to inform its future predictions.\n",
            "\n",
            "**\n",
            "________________________________________________________________________________\n",
            "Key Challenges in AI:**\n",
            "\n",
            "*   **Data Bias:** If the training data is biased, the AI model will also be biased.  This can lead to unfair or discriminatory outcomes.\n",
            "*   **Explainability:** It can be difficult to understand why an AI model made a particular decision.  This is especially true for deep learning\n",
            "________________________________________________________________________________\n",
            " models, which are often seen as \"black boxes.\"\n",
            "*   **Computational Resources:** Training large AI models requires enormous amounts of computing power.\n",
            "*   **Generalization:**  AI models can sometimes struggle to generalize to new situations that are different from the data they were trained on.\n",
            "*   **Ethical Considerations:**  \n",
            "________________________________________________________________________________\n",
            "AI raises many ethical concerns, such as job displacement, privacy, and the potential for misuse.\n",
            "\n",
            "**In summary:**\n",
            "\n",
            "AI, particularly the sophisticated models developed by OpenAI, works by learning complex patterns from vast amounts of data.  Deep learning, using neural networks and architectures like Transformers, is a core technology.  These\n",
            "________________________________________________________________________________\n",
            " models are trained to make predictions, generate text, create images, and perform other tasks by adjusting their internal parameters based on the data they are exposed to.  While incredibly powerful, AI also presents significant challenges related to data bias, explainability, and ethical considerations. The field is rapidly evolving, with new techniques and architectures\n",
            "________________________________________________________________________________\n",
            " constantly being developed.\n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content_stream(\n",
        "    model=MODEL,\n",
        "    contents=\"Explain how AI works, AI Model: openai\",\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"_\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZjfCkzSdcEc"
      },
      "source": [
        "#### Chat\n",
        "\n",
        "The SDK chat class provides an interface to keep track of conversation history. Behind the scenes it uses the same `generate_content` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCI8O9Ldjn6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87aa14e-69e9-4ed9-f76d-0464dde97c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That\n",
            "________________________________________________________________________________\n",
            "'s wonderful\n",
            "________________________________________________________________________________\n",
            "! Dogs are great companions. Tell me a little more about them! What kind of dogs are\n",
            "________________________________________________________________________________\n",
            " they? What are their names? How old are they? I'd love to\n",
            "________________________________________________________________________________\n",
            " hear about your furry friends!\n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "chat = client.chats.create(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    history=[\n",
        "        types.Content(role=\"user\", parts=[types.Part(text=\"Hello\")]),\n",
        "        types.Content(\n",
        "            role=\"model\",\n",
        "            parts=[\n",
        "                types.Part(\n",
        "                    text=\"Great to meet you. What would you like to know?\"\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "response = chat.send_message_stream(message=\"I have 2 dogs in my house.\")\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"_\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmfMuI44Kev2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46485525-cee8-49ef-bbf0-325e37f37042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Since\n",
            "________________________________________________________________________________\n",
            " you have two\n",
            "________________________________________________________________________________\n",
            " dogs, and each dog has four paws, there are a total of 8\n",
            "________________________________________________________________________________\n",
            " paws in your house (2 dogs * 4 paws/dog = 8\n",
            "________________________________________________________________________________\n",
            " paws).\n",
            "\n",
            "________________________________________________________________________________\n",
            "[Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Hello')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Great to meet you. What would you like to know?')], role='model'), UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I have 2 dogs in my house.')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='That')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\"'s wonderful\")], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='! Dogs are great companions. Tell me a little more about them! What kind of dogs are')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\" they? What are their names? How old are they? I'd love to\")], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=' hear about your furry friends!\\n')], role='model'), UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='How many paws are in my house?')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Since')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=' you have two')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=' dogs, and each dog has four paws, there are a total of 8')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=' paws in your house (2 dogs * 4 paws/dog = 8')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=' paws).\\n')], role='model')]\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message_stream(message=\"How many paws are in my house?\")\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"_\" * 80)\n",
        "\n",
        "print(chat.get_history())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_MkOG6uLs75"
      },
      "source": [
        "#### Parameters\n",
        "\n",
        "Every prompt you send to the model includes parameters that control how the model generates responses. You can configure these parameters, or let the model use the default options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_jk93Z-Lum-"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyrJ9ul7yuv"
      },
      "source": [
        "- `max_output_tokens`: Sets the maximum number of tokens to include in a candidate.\n",
        "- `temperature`: Controls the randomness of the output. Use higher values for more creative responses, and lower values for more deterministic responses. Values can range from [0.0, 2.0].\n",
        "- `top_p`: Changes how the model selects tokens for output. Tokens are selected from the most to least probable until the sum of their probabilities equals the top_p value.\n",
        "- `top_k`: Changes how the model selects tokens for output. A top_k of 1 means the selected token is the most probable among all the tokens in the model's vocabulary, while a top_k of 3 means that the next token is selected from among the 3 most probable using the temperature. Tokens are further filtered based on top_p with the final token selected using temperature sampling.\n",
        "- `stop_sequences`: List of strings  (up to 5) that tells the model to stop generating text if one of the strings is encountered in the response. If specified, the API will stop at the first appearance of a stop sequence.\n",
        "- `seed`: If specified, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9JgfKF8nvr"
      },
      "source": [
        "#### System instructions\n",
        "\n",
        "System instructions let you steer the behavior of a model based on your specific use case. When you provide system instructions, you give the model additional context to help it understand the task and generate more customized responses. The model should adhere to the system instructions over the full interaction with the user, enabling you to specify product-level behavior separate from the prompts provided by end users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CayVOonC8st5"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjdRzLbN-ANo"
      },
      "source": [
        "#### Long context and token counting\n",
        "\n",
        "Gemini 2.0 Flash and 2.5 Pro have a 1M token context window.\n",
        "\n",
        "In practice, 1 million tokens could look like:\n",
        "\n",
        "- 50,000 lines of code (with the standard 80 characters per line)\n",
        "- All the text messages you have sent in the last 5 years\n",
        "- 8 average length English novels\n",
        "- 1 hour of video data\n",
        "\n",
        "Let's feed in an entire book and ask questions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6pGhOkj-CFS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get(\"https://gutenberg.org/cache/epub/16317/pg16317.txt\")\n",
        "book = res.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0nnKaKC-NMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67765ef-2a86-4829-8423-26e9d326007c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Art of Public Speaking\r\n",
            "    \r\n",
            "This ebook is for the use of anyon\n"
          ]
        }
      ],
      "source": [
        "print(book[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ves9N2m-_k-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fc2ae8-ac53-469e-eafe-28e469e6606d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# charakters 979714\n",
            "# words 162461\n",
            "# tokens: ~216614\n"
          ]
        }
      ],
      "source": [
        "print(f\"# charakters {len(book)}\")\n",
        "print(f\"# words {len(book.split())}\")\n",
        "print(f\"# tokens: ~{int(len(book.split()) * 4/3)}\")   # rule of thumb: 100tokens=75words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hmtD77wMXdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb6e4c8-482b-4cc4-ed61-43659c3a5aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here is a 10-bullet-point summary of \"The Art of Public Speaking\" by J. Berg Esenwein and Dale Carnegie:\n",
            "\n",
            "*   **Overcome Fear with Practice and Subject Absorption:** Public speaking confidence comes from facing audiences frequently, not just reading about it. Focusing on your subject matter and knowing it well helps to minimize self-consciousness.\n",
            "*   **Avoid Monotony Through Vocal Variation:** Monotony is deadly to a speech. Conquer it by mastering the principles of emphasis, pitch, pace, and pause to create a dynamic and engaging delivery.\n",
            "*   **Master Emphasis and Subordination:** Emphasize important words through contrast (volume, pace, pitch) while subordinating less important words to guide the audience's attention effectively.\n",
            "*   **Vary Pitch to Engage the Audience:** Use continual changes in vocal pitch, from high to low, to add expression and prevent monotony. Different thoughts and emotions call for different pitches.\n",
            "*   **Change Pace for Impact:** Vary the tempo (speed) of your speech. A faster pace can convey excitement, while a slower pace adds emphasis and gravitas.\n",
            "*   **Use Pause Strategically:** The pause is not merely silence; it is a powerful tool. Use it to gather your thoughts, create suspense, and allow your audience to absorb key ideas.\n",
            "*   **Harness the Power of Inflection:**  Control the subtle upward and downward modulations *within* words and phrases to convey meaning and feeling beyond the literal words themselves.\n",
            "*   **Concentrate to Deliver Effectively:** Focus all mental energy on the current sentence you are speaking, rather than anticipating the next. This will result in naturalness and increase your impact.\n",
            "*   **Project Force Through Conviction and Wording:** Projecting force is achieved through a combination of inner conviction about your subject matter and the purposeful choice of language, short words and specific terms.\n",
            "*   **Use Feeling and Enthusiasm to Connect:**  Appeal to the emotions of your audience, expressing your own genuine passion and enthusiasm. Aim for naturalness by speaking and acting in such a way that expresses the ideas of your speech directly.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Summerize the book, REturn 10 bullet points\n",
        "\n",
        "{book}\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=prompt\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9NUCaexPqy"
      },
      "source": [
        "To understand the token usage, you can check\n",
        "\n",
        "\n",
        "`usage_metadata`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LAoNQ3Ys-CB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e4a61b-9658-4800-dc43-a5a23fbe93c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "441\n"
          ]
        }
      ],
      "source": [
        "print(response.usage_metadata.cached_content_token_count)\n",
        "print(response.usage_metadata.candidates_token_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jzrjfNDxUhZ"
      },
      "source": [
        "You can also use `count_tokens` to check the size of your input prompt(s):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIrVpB-Htc3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1185b2c3-8ce2-405a-92cb-36bfac44f126"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountTokensResponse(total_tokens=250554, cached_content_token_count=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "client.models.count_tokens(model=MODEL, contents=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE7MEKBI18K0"
      },
      "source": [
        "## !! Exercise: Chat with a book !!\n",
        "\n",
        "Task:\n",
        "- Create a chat\n",
        "- Use a system prompt: `\"You are an expert book reviewer with a witty tone.\"`\n",
        "- Use a temperature of `1.5`\n",
        "- Ask 1 to summarize the book\n",
        "- Ask 1 question to explain more detail about a certain topic from the book\n",
        "- Ask to create a social media post based on the book\n",
        "- Print the total number of tokens used during the chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKL0JNbCzY0P"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzBsZi5Fmgs"
      },
      "source": [
        "## Recap & Next steps\n",
        "\n",
        "Nice work! You learned\n",
        "- Python SDK quickstart\n",
        "- Text prompting\n",
        "- Streaming and chats\n",
        "- System prompts and config options\n",
        "- Long context and token counting\n",
        "\n",
        "\n",
        "More helpful resources:\n",
        "- [API docs quickstart](https://ai.google.dev/gemini-api/docs/quickstart?lang=python)\n",
        "- [Text generation docs](https://ai.google.dev/gemini-api/docs/text-generation)\n",
        "- [Long context docs](https://ai.google.dev/gemini-api/docs/long-context)\n",
        "\n",
        "Next steps:\n",
        "- [Part 2: Multimodal understanding (image, video, audio, docs, code)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-2-multimodal-understanding.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJvk8RBIffKz"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}